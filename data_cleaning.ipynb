{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feaed366-bbe8-49cf-ba9d-c81f85f81e84",
   "metadata": {},
   "source": [
    "# __Data Cleaning__\n",
    "Zhalae Daneshvari, Peyton Smith, Sunny Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be22b382",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "### What are the observations (rows) and the attributes (columns)?\n",
    "- **Observations:** Each row represents a unique combination of a census tract in New York State and a nearby retail food store.\n",
    "- **Attributes:** \n",
    "  - NAME: Census tract identifier\n",
    "  - median_income: Median household income of the census tract\n",
    "  - white_pop, black_pop, asian_pop, hispanic_pop: Population counts for each racial/ethnic group\n",
    "  - tract: Census tract number\n",
    "  - total_pop: Total population of the census tract\n",
    "  - white_percent, black_percent, asian_percent, hispanic_percent: Percentage of each racial/ethnic group in the tract\n",
    "  - nearest_store: Identifier for the nearest retail food store\n",
    "  - nearest_store_name: Name of the nearest retail food store\n",
    "  - distance_to_nearest_store: Distance in meters from the census tract centroid to the nearest store\n",
    "\n",
    "### Why was this dataset created?\n",
    "This dataset was created to facilitate the analysis of the relationship between socioeconomic factors, racial composition, and access to grocery stores in New York State. It combines census data with retail food store locations to enable the exploration of potential disparities in food accessibility across different demographic groups. The retail food stores dataset was created to provide insights into grocery stores licensed by New York State. Its purposes include promoting transparency, facilitating economic analysis, informing policy-making, and aiding in business planning. The U.S. Census data was created to collect detailed demographics and additional information on the composition of small areas (tracts) within the U.S. It serves various purposes including resource allocation, policy-making, and academic research.\n",
    "\n",
    "### Who funded the creation of the dataset?\n",
    "The dataset is a combination of data from the U.S. Census Bureau (government-funded) and the New York State Department of Agriculture and Markets. As a result, it's logical that the creation and collection of this data was funded by the government for the purpose of research and policy. The merging and preprocessing of these datasets was done for the purpose of research for our INFO 2950 Group Project.\n",
    "\n",
    "### What processes might have influenced what data was observed and recorded and what was not?\n",
    "1. Census data collection methods and potential underreporting in certain communities\n",
    "2. Licensing and registration processes for retail food stores, which may not capture all food sources\n",
    "3. Definition of what constitutes a retail food store, potentially excluding some food sources\n",
    "4. Geospatial calculation methods used to determine nearest stores and distances\n",
    "5. The use of census tract centroids as proxies for residential locations, which may not accurately represent all residents' locations within a tract\n",
    "\n",
    "### What preprocessing was done, and how did the data come to be in the form that you are using?\n",
    "1. Merging of census tract data with retail food store location data\n",
    "2. Calculation of racial/ethnic percentages from population counts\n",
    "3. Geospatial analysis to determine the nearest store and its distance for each census tract\n",
    "5. Data cleaning to handle missing values or outliers\n",
    "\n",
    "### If people are involved, were they aware of the data collection and if so, what purpose did they expect the data to be used for?\n",
    "People involved in the census data collection were aware and expected it to be used for various governmental and public purposes. Store owners providing information for licensing were aware of data collection for regulatory purposes. However, individuals were likely unaware of the specific use of this data for analyzing food accessibility disparities based on race and income.\n",
    "\n",
    "### Where can your raw source data be found?\n",
    "The raw census data can be accessed through the U.S. Census Bureau's API. https://www.census.gov/data/developers/guidance/api-user-guide.html\n",
    "\n",
    "The raw retail food store data can be found on the New York State Open Data portal: https://data.ny.gov/Economic-Development/Retail-Food-Stores/9a8c-vfzj/about_data\n",
    "\n",
    "The merged and preprocessed dataset (merged_census_store_data.csv) used for this analysis is stored within the git repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208c3b6f-e12b-475e-bbc2-f1b10eea461e",
   "metadata": {},
   "source": [
    "### Importing\n",
    "First run 'pip install numpy seaborn pandas matplotlib requests geopandas shapely duckdb' in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6122562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /home/codespace/.local/lib/python3.12/site-packages (from geopandas) (2.1.1)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from geopandas) (0.10.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from geopandas) (24.1)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from geopandas) (2.2.3)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from geopandas) (3.7.0)\n",
      "Requirement already satisfied: shapely>=2.0.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from geopandas) (2.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from pyogrio>=0.7.2->geopandas) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: duckdb in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install geopandas\n",
    "! pip install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c173e63d-9b54-4c36-8226-02a24a0e7c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "import os\n",
    "import duckdb as db\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from shapely.geometry import Point\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30ce5ee",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb80469e",
   "metadata": {},
   "source": [
    "### Data Cleaning: Retail Food Stores in New York State\n",
    "Source List of Grocery Stores Provided by New York State:\n",
    "\n",
    "https://data.ny.gov/Economic-Development/Retail-Food-Stores/9a8c-vfzj/about_data\n",
    "\n",
    "This contains a csv file of every grocery store location in New York state that could be then paired with census tract data to look at how average distance to grocery stores changes by different socioeconomic groups. We will use census tract centers as an approximation for where everyone in the tract lives and then use the census data to get information on population statistics.\n",
    "\n",
    "#### Step 1: Loading in the Data\n",
    "\n",
    "Our primary grocery store dataset comes from the New York State Open Data portal, specifically the \"Retail Food Stores\" dataset. This dataset provides information about licensed retail food stores across New York State. This step loads our raw data into a pandas DataFrame. Understanding the initial shape is to check later on that our cleaning is actaully changing the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bebecc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset shape: (24221, 15)\n"
     ]
    }
   ],
   "source": [
    "# Loading in the dataset\n",
    "stores = pd.read_csv('https://data.ny.gov/api/views/9a8c-vfzj/rows.csv?accessType=DOWNLOAD')\n",
    "\n",
    "# Displays the shape of the original raw data for the retail stores\n",
    "print(\"Initial dataset shape:\", stores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b169c",
   "metadata": {},
   "source": [
    "#### Step 2: Selecting Relevant Columns\n",
    "For our analysis of grocery store access we really only need the store name and location as this will be used to find the distance of how far the store is from the center of the census tract. We will extract these from the 'Entity Name' and 'Georeference' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b76079f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   name                        georeference\n",
      "0         ANK PETRO INC   POINT (-73.816249346 42.46925125)\n",
      "1           EVANS JULIA  POINT (-73.949128787 42.577416307)\n",
      "2            HUBRIX LLC  POINT (-77.795356304 42.158830586)\n",
      "3       REID STORES INC  POINT (-78.277036649 42.220633641)\n",
      "4  361 DELI GROCERY LLC  POINT (-73.877219853 40.871759695)\n"
     ]
    }
   ],
   "source": [
    "# Selecting relevant columns\n",
    "stores = stores[['Entity Name', 'Georeference']]\n",
    "\n",
    "# Renaming the columns for clarity\n",
    "stores = stores.rename(columns={'Entity Name': 'name', \"Georeference\": \"georeference\"})\n",
    "\n",
    "print(stores.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa672609",
   "metadata": {},
   "source": [
    "#### Step 3: Handling Missing Data\n",
    "To ensure the accuracy of our spatial analysis in the next steps, we need to clean the data table to remove any stores with missing location data by dropping the NaN values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c204a7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after removing missing georeference values:(24221, 2)\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing Georeference\n",
    "stores = stores.dropna(subset=['georeference'])\n",
    "\n",
    "print(\"Dataset shape after removing missing georeference values:\" + str(stores.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c5b733",
   "metadata": {},
   "source": [
    "#### Step 4: Extracting Latitude and Longitude from Georeference\n",
    "To make the location data a more usuable format that we can calculate distance with with the census tract data, we have to extract the latitude and longitude from the Georeference column into their own separate columns, and then drop that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9862298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   name  longitude   latitude\n",
      "0         ANK PETRO INC -73.816249  42.469251\n",
      "1           EVANS JULIA -73.949129  42.577416\n",
      "2            HUBRIX LLC -77.795356  42.158831\n",
      "3       REID STORES INC -78.277037  42.220634\n",
      "4  361 DELI GROCERY LLC -73.877220  40.871760\n"
     ]
    }
   ],
   "source": [
    "# Extract latitude and longitude from Georeference\n",
    "def extract_coordinates(georeference):\n",
    "    coords = georeference.strip('POINT ()').split() #this works because same amount of numbers for both latitude and longitude\n",
    "    return pd.Series({'longitude': float(coords[0]), 'latitude': float(coords[1])}) #convert to float for ease of calculations\n",
    "\n",
    "stores[['longitude', 'latitude']] = stores['georeference'].apply(extract_coordinates)\n",
    "\n",
    "# Dropping the OG Georeference column \n",
    "stores = stores.drop('georeference', axis=1)\n",
    "\n",
    "print(stores.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c9db22",
   "metadata": {},
   "source": [
    "#### Step 5: Cleaned Retail Grocery Store Data Check\n",
    "Our final dataset contains the name, latitude, and longitude of each retail food store in New York State. This data set will be used to calculate distances between stores and census tract centroids.\n",
    "\n",
    "When combined with census data, this will enable us to investigate how store locations correlate with various socioeconomic factors, addressing our research questions about food access across different demographic groups in New York State.\n",
    "\n",
    "The next steps are to merge this cleaned store data with census tract data to begin our analysis of the relationship between store locations and socioeconomic factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7736476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset shape: (24221, 3)\n",
      "Cleaned column names: ['name', 'longitude', 'latitude']\n",
      "First few rows of the cleaned dataset:\n",
      "                   name  longitude   latitude\n",
      "0         ANK PETRO INC -73.816249  42.469251\n",
      "1           EVANS JULIA -73.949129  42.577416\n",
      "2            HUBRIX LLC -77.795356  42.158831\n",
      "3       REID STORES INC -78.277037  42.220634\n",
      "4  361 DELI GROCERY LLC -73.877220  40.871760\n"
     ]
    }
   ],
   "source": [
    "# Info about the cleaned grocery stores dataset\n",
    "print(\"Cleaned dataset shape:\", stores.shape)\n",
    "print(\"Cleaned column names: \" + str(stores.columns.tolist()))\n",
    "\n",
    "# First few rows of cleaned grocery dataset\n",
    "print(\"First few rows of the cleaned dataset:\")\n",
    "print(stores.head().to_string())\n",
    "\n",
    "# Saving the cleaned dataset to a csv file to use later \n",
    "stores.to_csv('cleaned_retail_stores.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e65fa6b",
   "metadata": {},
   "source": [
    "### Data Cleaning: Census Data for New York State\n",
    "\n",
    "#### Step 1: Loading in Census Data through Census API\n",
    "\n",
    "We'll use the Census API to collect demographic data for New York State census tracts, focusing on median household income and racial composition data. This step retrieves census data for all tracts in New York State, including median household income and population counts by race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c6b7a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created new dataframe.\n"
     ]
    }
   ],
   "source": [
    "# Census API endpoint and parameters\n",
    "api_key = \"273983b851bd05f546e743ac334b18277e8c67d1\"  \n",
    "base_url = \"https://api.census.gov/data/2021/acs/acs5\"\n",
    "variables = [\"NAME\", \"B19013_001E\", \"B02001_002E\", \"B02001_003E\", \"B02001_005E\", \"B03003_003E\"] #codes for median income as well as different racial category populations: white, black, hispanic, asian\n",
    "state = \"36\" #code for NY State\n",
    "\n",
    "# API URL\n",
    "url = f\"{base_url}?get={','.join(variables)}&for=tract:*&in=state:{state}&key={api_key}\"\n",
    "\n",
    "# Making the API request\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "\n",
    "    # Creating the DataFrame\n",
    "    census_df = pd.DataFrame(data[1:], columns=data[0])\n",
    "    print(\"Successfully created new dataframe.\")\n",
    "else:\n",
    "    print(f\"Error: Unable to get data. Status code: {response.status_code}\")\n",
    "    print(response.text)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5570c6bc",
   "metadata": {},
   "source": [
    "#### Step 2: Renaming and Selecting Columns\n",
    "Renaming the columns to names that make sense to the average person and select only the ones we need for our analysis. This step focuses our dataset on the demographic information relevant to our research question about food access across different socioeconomic groups which in this case is the median income, white population, black population, asian population, and hispanic population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa113822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         name median_income white_pop  \\\n",
      "0     Census Tract 1, Albany County, New York         44871       530   \n",
      "1  Census Tract 2.01, Albany County, New York         42456       521   \n",
      "2  Census Tract 2.02, Albany County, New York         24792       124   \n",
      "3  Census Tract 3.01, Albany County, New York         40666      1155   \n",
      "4  Census Tract 3.02, Albany County, New York         42370      2180   \n",
      "\n",
      "  black_pop asian_pop hispanic_pop   tract state county        GEOID  \n",
      "0      1086        87          311  000100    36    001  36001000100  \n",
      "1      1945       109          165  000201    36    001  36001000201  \n",
      "2      2316         0           71  000202    36    001  36001000202  \n",
      "3      1251       221          836  000301    36    001  36001000301  \n",
      "4       457       387          155  000302    36    001  36001000302  \n"
     ]
    }
   ],
   "source": [
    "# Renaming the columns\n",
    "column_names = {\n",
    "    \"NAME\": \"name\",\n",
    "    \"B19013_001E\": \"median_income\",\n",
    "    \"B02001_002E\": \"white_pop\",\n",
    "    \"B02001_003E\": \"black_pop\",\n",
    "    \"B02001_005E\": \"asian_pop\",\n",
    "    \"B03003_003E\": \"hispanic_pop\"\n",
    "}\n",
    "\n",
    "census_df = census_df.rename(columns=column_names)\n",
    "\n",
    "# Selecting the relevant columns\n",
    "census_df = census_df[[\"name\", \"median_income\", \"white_pop\", \"black_pop\", \"asian_pop\", \"hispanic_pop\", \"tract\", \"state\", \"county\"]]\n",
    "\n",
    "#adding GEOID values for matching \n",
    "census_df[\"GEOID\"] = census_df[\"state\"] + census_df[\"county\"] + census_df[\"tract\"]\n",
    "print(census_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2111b5b7",
   "metadata": {},
   "source": [
    "#### Step 3: Data Type Conversion\n",
    "We need to convert the numeric columns to the appropriate data type for analysis which in this case is a float as we will be calculating the percentage of the racial populations in a future step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82eeac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types after conversion:\n",
      "name              object\n",
      "median_income    float64\n",
      "white_pop        float64\n",
      "black_pop        float64\n",
      "asian_pop        float64\n",
      "hispanic_pop     float64\n",
      "tract             object\n",
      "state             object\n",
      "county            object\n",
      "GEOID             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Converting the numeric columns to float values\n",
    "numeric_columns = [\"median_income\", \"white_pop\", \"black_pop\", \"asian_pop\", \"hispanic_pop\"]\n",
    "census_df[numeric_columns] = census_df[numeric_columns].astype(float)\n",
    "\n",
    "#Sanity check\n",
    "print(\"Data types after conversion:\")\n",
    "print(census_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547f2fb6",
   "metadata": {},
   "source": [
    "#### Step 3: Handling Missing Values\n",
    "Checking for and handle any missing values in our dataset as that would lead to problems when plotting the data later on and do not want to use data that misses crucial info for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ec390cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "name             0\n",
      "median_income    0\n",
      "white_pop        0\n",
      "black_pop        0\n",
      "asian_pop        0\n",
      "hispanic_pop     0\n",
      "tract            0\n",
      "state            0\n",
      "county           0\n",
      "GEOID            0\n",
      "dtype: int64\n",
      "(5198, 10)\n"
     ]
    }
   ],
   "source": [
    "# Replace -666666666 (Census placeholder for missing data) with NaN\n",
    "census_df = census_df.replace(-666666666, np.nan)\n",
    "\n",
    "# Drop the rows with the missing median income\n",
    "census_df = census_df.dropna(subset=[\"median_income\"])\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(census_df.isnull().sum())\n",
    "\n",
    "# Dataset shape after handling missing values \n",
    "print(census_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d205344",
   "metadata": {},
   "source": [
    "#### Step 4: Creating Percentage variables per racial group\n",
    "Creating percentage variables for racial composition in the census tracts to help with our analysis of whether closest grocert store distance changes based on race in NY state census tracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd28fb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         name  median_income  white_pop  \\\n",
      "0     Census Tract 1, Albany County, New York        44871.0      530.0   \n",
      "1  Census Tract 2.01, Albany County, New York        42456.0      521.0   \n",
      "2  Census Tract 2.02, Albany County, New York        24792.0      124.0   \n",
      "3  Census Tract 3.01, Albany County, New York        40666.0     1155.0   \n",
      "4  Census Tract 3.02, Albany County, New York        42370.0     2180.0   \n",
      "\n",
      "   black_pop  asian_pop  hispanic_pop   tract state county        GEOID  \\\n",
      "0     1086.0       87.0         311.0  000100    36    001  36001000100   \n",
      "1     1945.0      109.0         165.0  000201    36    001  36001000201   \n",
      "2     2316.0        0.0          71.0  000202    36    001  36001000202   \n",
      "3     1251.0      221.0         836.0  000301    36    001  36001000301   \n",
      "4      457.0      387.0         155.0  000302    36    001  36001000302   \n",
      "\n",
      "   total_pop  white_percent  black_percent  asian_percent  hispanic_percent  \n",
      "0     2014.0      26.315789      53.922542       4.319762         15.441907  \n",
      "1     2740.0      19.014599      70.985401       3.978102          6.021898  \n",
      "2     2511.0       4.938272      92.234170       0.000000          2.827559  \n",
      "3     3463.0      33.352584      36.124747       6.381750         24.140918  \n",
      "4     3179.0      68.575024      14.375590      12.173640          4.875747  \n"
     ]
    }
   ],
   "source": [
    "# Calculate total population\n",
    "census_df[\"total_pop\"] = census_df[[\"white_pop\", \"black_pop\", \"asian_pop\", \"hispanic_pop\"]].sum(axis=1)\n",
    "\n",
    "# Calculate percentage for each race/ethnicity\n",
    "for group in [\"white\", \"black\", \"asian\", \"hispanic\"]:\n",
    "    census_df[f\"{group}_percent\"] = census_df[f\"{group}_pop\"] / census_df[\"total_pop\"] * 100\n",
    "\n",
    "print(census_df.head())\n",
    "\n",
    "# Saving the cleaned census data\n",
    "census_df.to_csv('cleaned_census_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d943011",
   "metadata": {},
   "source": [
    "#### Step 5: Finding Center of Census Tracts \n",
    "Now that we have a cleaned dataset we have to find the center of each census tract to serve as a proxy to where everyone in that census tract lives and in turn how far they are from a grocery store. \n",
    "We looked up how to find the center of each census tract and ended up using the .centroid function (sources linked at bottom of notebook). The first thing done was to get the points in actual gps coordinates so that proper distance could be calculated. We then created two new columns one for the center point and one for the tract number. The tract column is needed to merge the data with the census information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "973a7938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          centroid        GEOID\n",
      "0  POINT (1835948.861 2171541.933)  36047069601\n",
      "1  POINT (1836565.723 2171170.171)  36047069602\n",
      "2   POINT (1831518.497 2174267.51)  36047079801\n",
      "3  POINT (1831354.054 2173996.174)  36047079802\n",
      "4  POINT (1838171.439 2174599.774)  36047105801\n"
     ]
    }
   ],
   "source": [
    "#Load in shapefile for New York Census Tracts \n",
    "shapefile_path = \"tl_2021_36_tract.shp\"  #must be in same folder as ipynb file\n",
    "tracts_gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "#gets points in gps plane \n",
    "tracts_gdf = tracts_gdf.to_crs(epsg=5070)\n",
    "\n",
    "# Calculates centroids for each census tract\n",
    "tracts_gdf['centroid'] = tracts_gdf.geometry.centroid\n",
    "\n",
    "#gets tract number so can match with census information last 6 values of GEOID information census data \n",
    "tracts_gdf['tract'] = tracts_gdf['GEOID'].str[-6:]\n",
    "\n",
    "# Take out tract number and centroid columns\n",
    "centroid_df = tracts_gdf[['centroid', \"GEOID\"]]\n",
    "print(centroid_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29b324f",
   "metadata": {},
   "source": [
    "#### Step 6: Merging DataFrames \n",
    "The US census data needs to be merged with data on the center of each census tract. The data is merged on tract values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9032fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame:\n",
      "                                         name  median_income  white_pop  \\\n",
      "0     Census Tract 1, Albany County, New York        44871.0      530.0   \n",
      "1  Census Tract 2.01, Albany County, New York        42456.0      521.0   \n",
      "2  Census Tract 2.02, Albany County, New York        24792.0      124.0   \n",
      "3  Census Tract 3.01, Albany County, New York        40666.0     1155.0   \n",
      "4  Census Tract 3.02, Albany County, New York        42370.0     2180.0   \n",
      "\n",
      "   black_pop  asian_pop  hispanic_pop   tract state county        GEOID  \\\n",
      "0     1086.0       87.0         311.0  000100    36    001  36001000100   \n",
      "1     1945.0      109.0         165.0  000201    36    001  36001000201   \n",
      "2     2316.0        0.0          71.0  000202    36    001  36001000202   \n",
      "3     1251.0      221.0         836.0  000301    36    001  36001000301   \n",
      "4      457.0      387.0         155.0  000302    36    001  36001000302   \n",
      "\n",
      "   total_pop  white_percent  black_percent  asian_percent  hispanic_percent  \\\n",
      "0     2014.0      26.315789      53.922542       4.319762         15.441907   \n",
      "1     2740.0      19.014599      70.985401       3.978102          6.021898   \n",
      "2     2511.0       4.938272      92.234170       0.000000          2.827559   \n",
      "3     3463.0      33.352584      36.124747       6.381750         24.140918   \n",
      "4     3179.0      68.575024      14.375590      12.173640          4.875747   \n",
      "\n",
      "                         centroid  \n",
      "0  POINT (1797479.33 2397226.777)  \n",
      "1  POINT (1796256.32 2395723.449)  \n",
      "2  POINT (1796447.88 2396760.666)  \n",
      "3  POINT (1794187.135 2396866.61)  \n",
      "4  POINT (1793414.167 2397752.83)  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'GEOID' is of string type in both DataFrames\n",
    "census_df['GEOID'] = census_df['GEOID'].astype(str)\n",
    "centroid_df['GEOID'] = centroid_df['GEOID'].astype(str)\n",
    "\n",
    "# Merge the DataFrames on 'GEOID' using an inner join\n",
    "merged_df = pd.merge(census_df, centroid_df, on='GEOID', how='inner')\n",
    "\n",
    "# Print the first few rows of the merged DataFrame\n",
    "print(\"Merged DataFrame:\")\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae5f68c",
   "metadata": {},
   "source": [
    "#### Step 7: Calculating closest grocery store's average distance to each census tract\n",
    "Now the closest grocery store and the average distance to each census tract needs to be found as that is the main focus and variable of our research question. \n",
    "\n",
    "In this step we faced significant challenges due to the need to work with and convert between different types of geometries (polygons for census tracts and points for store locations) and coordinate reference systems (projected CRS EPSG:5070 for census data and geographic CRS EPSG:4326 for store locations). To perform accurate distance calculations, we had to convert all geometries to a common CRS, calculate tract centroids from polygons, and then perform point-to-point distance calculations, all while accounting for the Earth's curvature. The large number of spatial computations required for calculating average distances from census tract centroids to grocery stores further complicated the process. To overcome these challenges, we utilized the GeoPandas library, which extends pandas to handle geospatial data, allowing us to efficiently perform CRS transformations, centroid calculations, spatial joins between census tracts and store locations, and calculate accurate geodesic distances using the pyproj library for cartographic projections and coordinate transformations. \n",
    "\n",
    "We learned how to do a lot of this from the sources listed in references column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "386688ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroid data:\n",
      "    tract        GEOID  longitude   latitude\n",
      "0  069601  36047069601 -73.914786  40.627228\n",
      "1  069602  36047069602 -73.908651  40.622730\n",
      "2  079801  36047079801 -73.958719  40.660011\n",
      "3  079802  36047079802 -73.961371  40.657991\n",
      "4  105801  36047105801 -73.880596  40.649220\n",
      "Stores data:\n",
      "                   name  longitude   latitude\n",
      "0         ANK PETRO INC -73.816249  42.469251\n",
      "1           EVANS JULIA -73.949129  42.577416\n",
      "2            HUBRIX LLC -77.795356  42.158831\n",
      "3       REID STORES INC -78.277037  42.220634\n",
      "4  361 DELI GROCERY LLC -73.877220  40.871760\n",
      "Centroid data with nearest store and distance:\n",
      "    tract        GEOID  longitude   latitude                        geometry  \\\n",
      "0  069601  36047069601 -73.914786  40.627228  POINT (591781.302 4497943.187)   \n",
      "1  069602  36047069602 -73.908651  40.622730  POINT (592306.371 4497450.251)   \n",
      "2  079801  36047079801 -73.958719  40.660011  POINT (588022.553 4501537.351)   \n",
      "3  079802  36047079802 -73.961371  40.657991   POINT (587800.97 4501310.438)   \n",
      "4  105801  36047105801 -73.880596  40.649220  POINT (594641.881 4500420.695)   \n",
      "\n",
      "   nearest_store_index      nearest_store_name  distance_to_nearest_store  \n",
      "0                15784         L & T SUSHI LLC                 165.315035  \n",
      "1                14369  ALMONTE MILL FOOD CORP                 624.099569  \n",
      "2                 4997     HK FRUIT MARKET INC                 144.323987  \n",
      "3                13395        HABIB I DELI INC                  95.432770  \n",
      "4                 9051          CVS ALBANY LLC                 302.382437  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tract</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>geometry</th>\n",
       "      <th>nearest_store_index</th>\n",
       "      <th>nearest_store_name</th>\n",
       "      <th>distance_to_nearest_store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>069601</td>\n",
       "      <td>36047069601</td>\n",
       "      <td>-73.914786</td>\n",
       "      <td>40.627228</td>\n",
       "      <td>POINT (-73.91479 40.62723)</td>\n",
       "      <td>15784</td>\n",
       "      <td>L &amp; T SUSHI LLC</td>\n",
       "      <td>165.315035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>069602</td>\n",
       "      <td>36047069602</td>\n",
       "      <td>-73.908651</td>\n",
       "      <td>40.622730</td>\n",
       "      <td>POINT (-73.90865 40.62273)</td>\n",
       "      <td>14369</td>\n",
       "      <td>ALMONTE MILL FOOD CORP</td>\n",
       "      <td>624.099569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>079801</td>\n",
       "      <td>36047079801</td>\n",
       "      <td>-73.958719</td>\n",
       "      <td>40.660011</td>\n",
       "      <td>POINT (-73.95872 40.66001)</td>\n",
       "      <td>4997</td>\n",
       "      <td>HK FRUIT MARKET INC</td>\n",
       "      <td>144.323987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>079802</td>\n",
       "      <td>36047079802</td>\n",
       "      <td>-73.961371</td>\n",
       "      <td>40.657991</td>\n",
       "      <td>POINT (-73.96137 40.65799)</td>\n",
       "      <td>13395</td>\n",
       "      <td>HABIB I DELI INC</td>\n",
       "      <td>95.432770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105801</td>\n",
       "      <td>36047105801</td>\n",
       "      <td>-73.880596</td>\n",
       "      <td>40.649220</td>\n",
       "      <td>POINT (-73.8806 40.64922)</td>\n",
       "      <td>9051</td>\n",
       "      <td>CVS ALBANY LLC</td>\n",
       "      <td>302.382437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tract        GEOID  longitude   latitude                    geometry  \\\n",
       "0  069601  36047069601 -73.914786  40.627228  POINT (-73.91479 40.62723)   \n",
       "1  069602  36047069602 -73.908651  40.622730  POINT (-73.90865 40.62273)   \n",
       "2  079801  36047079801 -73.958719  40.660011  POINT (-73.95872 40.66001)   \n",
       "3  079802  36047079802 -73.961371  40.657991  POINT (-73.96137 40.65799)   \n",
       "4  105801  36047105801 -73.880596  40.649220   POINT (-73.8806 40.64922)   \n",
       "\n",
       "   nearest_store_index      nearest_store_name  distance_to_nearest_store  \n",
       "0                15784         L & T SUSHI LLC                 165.315035  \n",
       "1                14369  ALMONTE MILL FOOD CORP                 624.099569  \n",
       "2                 4997     HK FRUIT MARKET INC                 144.323987  \n",
       "3                13395        HABIB I DELI INC                  95.432770  \n",
       "4                 9051          CVS ALBANY LLC                 302.382437  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Extracting the tract number and centroid columns\n",
    "centroid_df = tracts_gdf[['tract', 'centroid','GEOID']].copy()\n",
    "\n",
    "# Converting the centroids to latitude and longitude (WGS84, EPSG:4326)\n",
    "centroid_df['centroid'] = centroid_df['centroid'].to_crs(epsg=4326)\n",
    "\n",
    "# Extracting the latitude and longitude from the centroid points\n",
    "centroid_df['longitude'] = centroid_df['centroid'].x\n",
    "centroid_df['latitude'] = centroid_df['centroid'].y\n",
    "\n",
    "# Dropping the original centroid column because it's no longer needed\n",
    "centroid_df = centroid_df.drop(['centroid'], axis=1)\n",
    "\n",
    "print(\"Centroid data:\")\n",
    "print(centroid_df.head())\n",
    "\n",
    "# Loading the stores data\n",
    "stores = pd.read_csv('cleaned_retail_stores.csv')\n",
    "\n",
    "print(\"Stores data:\")\n",
    "print(stores.head())\n",
    "\n",
    "# Creating the GeoDataFrames for both datasets\n",
    "centroid_gdf = gpd.GeoDataFrame(\n",
    "    centroid_df,\n",
    "    geometry=gpd.points_from_xy(centroid_df.longitude, centroid_df.latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "stores_gdf = gpd.GeoDataFrame(\n",
    "    stores,\n",
    "    geometry=gpd.points_from_xy(stores.longitude, stores.latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Convert both GeoDataFrames to a projected CRS for distance calculation\n",
    "centroid_gdf = centroid_gdf.to_crs(epsg=32618)\n",
    "stores_gdf = stores_gdf.to_crs(epsg=32618)\n",
    "\n",
    "# Finding the nearest grocery store to each census tract centroid\n",
    "centroid_gdf['nearest_store_index'] = centroid_gdf.geometry.apply(\n",
    "    lambda geom: stores_gdf.distance(geom).idxmin()\n",
    ")\n",
    "centroid_gdf['nearest_store_name'] = centroid_gdf['nearest_store_index'].apply(\n",
    "    lambda idx: stores_gdf.loc[idx, 'name']\n",
    ")\n",
    "\n",
    "# Calculating the distance to the nearest store (in meters)\n",
    "centroid_gdf['distance_to_nearest_store'] = centroid_gdf.geometry.apply(\n",
    "    lambda geom: stores_gdf.loc[stores_gdf.distance(geom).idxmin()].geometry.distance(geom)\n",
    ")\n",
    "\n",
    "print(\"Centroid data with nearest store and distance:\")\n",
    "print(centroid_gdf.head())\n",
    "\n",
    "# Converting back to WGS84 format for final output\n",
    "centroid_gdf = centroid_gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Saving the result in a CSV file\n",
    "centroid_gdf.to_csv('census_tracts_with_nearest_store.csv', index=False)\n",
    "\n",
    "# Display the result\n",
    "centroid_gdf.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151b53e8",
   "metadata": {},
   "source": [
    "#### Step 8. Cleaning and merging the nearest grocery store data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7acfe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   median_income  white_pop  black_pop  asian_pop  hispanic_pop  county  \\\n",
      "0        44871.0      530.0     1086.0       87.0         311.0       1   \n",
      "1        42456.0      521.0     1945.0      109.0         165.0       1   \n",
      "2        24792.0      124.0     2316.0        0.0          71.0       1   \n",
      "3        40666.0     1155.0     1251.0      221.0         836.0       1   \n",
      "4        42370.0     2180.0      457.0      387.0         155.0       1   \n",
      "\n",
      "         GEOID  total_pop  white_percent  black_percent  asian_percent  \\\n",
      "0  36001000100     2014.0      26.315789      53.922542       4.319762   \n",
      "1  36001000201     2740.0      19.014599      70.985401       3.978102   \n",
      "2  36001000202     2511.0       4.938272      92.234170       0.000000   \n",
      "3  36001000301     3463.0      33.352584      36.124747       6.381750   \n",
      "4  36001000302     3179.0      68.575024      14.375590      12.173640   \n",
      "\n",
      "   hispanic_percent  County  nearest_store_index  \\\n",
      "0         15.441907  ALBANY                10543   \n",
      "1          6.021898  ALBANY                12838   \n",
      "2          2.827559  ALBANY                 2351   \n",
      "3         24.140918  ALBANY                10844   \n",
      "4          4.875747  ALBANY                 1594   \n",
      "\n",
      "                   nearest_store_name  distance_to_nearest_store  tract  \n",
      "0                      AMROS DELI LLC                 616.950435    100  \n",
      "1                     ALAWDI ADEL ALI                 114.000176    201  \n",
      "2     HOT BITES GROCERY & GOURMET INC                 719.604020    202  \n",
      "3  PRINCE CORNER DELI&GROCERY INC THE                 121.064383    301  \n",
      "4                        7-ELEVEN INC                 349.631178    302  \n"
     ]
    }
   ],
   "source": [
    "# Loading the new census grocery store distance CSV file\n",
    "store_distance_df = pd.read_csv('census_tracts_with_nearest_store.csv')\n",
    "\n",
    "# Loading the cleaned census data CSV file\n",
    "census_data_df = pd.read_csv('cleaned_census_data.csv')\n",
    "\n",
    "# Ensure the GEOID number columns in both dataframes are of the same type (str)\n",
    "store_distance_df['GEOID'] = store_distance_df['GEOID'].astype(str)\n",
    "census_data_df['GEOID'] = census_data_df['GEOID'].astype(str)\n",
    "\n",
    "# Extract county name from the 'NAME' column, create a new 'county' column, and make names uppercase\n",
    "census_data_df['County'] = (\n",
    "    census_data_df['name']\n",
    "    .str.extract(r',\\s(.*?)\\sCounty')[0]\n",
    "    .str.upper()\n",
    ")\n",
    "\n",
    "# Merging the dataframes on the GEOID number\n",
    "merged_df = pd.merge(census_data_df, store_distance_df, on='GEOID', how='left')\n",
    "\n",
    "# Dropping the unnecessary columns because they will not be used in the analysis\n",
    "merged_df['tract']=merged_df['tract_x']\n",
    "columns_to_drop = ['longitude', 'latitude', 'geometry', 'state', 'name','tract_x','tract_y']\n",
    "merged_df = merged_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Display the first few rows to verify changes\n",
    "print(merged_df.head())\n",
    "\n",
    "# Saving the merged dataframe to a new CSV file\n",
    "output_file = 'merged_census_store_data.csv'\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01427ff3-c8b5-4bf2-b8f2-6a52a2fc66fe",
   "metadata": {},
   "source": [
    "# Data Limitations\n",
    "\n",
    "### 1. Oversimplification of Racial and Ethnic Categories:\n",
    "The broad racial categories (white, black, Asian, Hispanic) may not capture the nuanced food access issues faced by specific ethnic subgroups or multiracial individuals.\n",
    "\n",
    "**Impact**: This simplification could lead to overlooking cultural factors in food access and potentially misguide policy interventions aimed at improving food equity among diverse communities.\n",
    "\n",
    "\n",
    "### 2. Limitations of Distance-Based Accessibility Measures:\n",
    "\n",
    "Our analysis uses straight-line distances rather than actual travel routes such as roads, and doesn't account for transportation modes or barriers like highways or rivers.\n",
    "\n",
    "**Impact**: This could significantly underestimate travel times and difficulties in accessing stores, especially in areas with complex urban layouts or for individuals relying on public transportation.\n",
    "\n",
    "\n",
    "### 3. Exclusion of Food Quality and Affordability:\n",
    "\n",
    "Our dataset focuses on the presence of stores but doesn't account for the quality, variety, or affordability of food offered.\n",
    "\n",
    "**Impact**: This limitation could lead to overestimating true food access in areas where stores are present but don't offer healthy or affordable options, potentially masking issues of nutritional inequality.\n",
    "\n",
    "\n",
    "### 4. Absence of Online and Mobile Food Services:\n",
    "\n",
    "The focus on physical store locations doesn't account for the growing influence of online grocery delivery services and mobile food markets.\n",
    "\n",
    "**Impact**: This omission could lead to underestimating food access in areas well-served by these alternative food sources, potentially skewing our understanding of modern food accessibility patterns.\n",
    "\n",
    "\n",
    "### 5. Lack of Consideration for Informal Food Networks:\n",
    "\n",
    "Our analysis doesn't capture informal food sources like community gardens, food sharing networks, or farmers' markets.\n",
    "\n",
    "**Impact**: This could lead to underestimating food resources in some communities, particularly in areas with strong social networks or alternative food systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bd2b96",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Geopandas intro tutorial:\n",
    "https://geopandas.org/en/stable/getting_started/introduction.html\n",
    "\n",
    "Spacial data links: \n",
    "https://walker-data.com/posts/proximity-analysis/\n",
    "https://michaelminn.net/tutorials/python-proximity/index.html\n",
    "\n",
    "Geopandas, for geospatial operations in Python, guide to getting started:\n",
    "https://geopandas.org/en/stable/getting_started/introduction.html\n",
    "https://geopandas.org/en/stable/docs/user_guide.html\n",
    "\n",
    "Shapely for geometric operations:\n",
    "https://shapely.readthedocs.io/en/stable/manual.html \n",
    "\n",
    "Conducting Geospatial Analysis in GeoPandas:\n",
    "https://geog-312.gishub.org/book/geospatial/geopandas.html \n",
    "\n",
    "Figuring out pd.DF.apply: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html\n",
    "\n",
    "Using Lambda function to PD Dataframes:\n",
    "https://www.geeksforgeeks.org/applying-lambda-functions-to-pandas-dataframe/\n",
    "\n",
    "Coordinate Reference Systems Info:\n",
    "https://docs.qgis.org/latest/en/docs/gentle_gis_introduction/coordinate_reference_systems.html\n",
    "\n",
    "Geopandas and Shapeley guide:\n",
    "https://www.learndatasci.com/tutorials/geospatial-data-python-geopandas-shapely/ \n",
    "\n",
    "API Sources: \n",
    "https://pygis.io/docs/d_access_census.html\n",
    "https://n8henrie.com/uploads/2017/11/plotting-us-census-data-with-python-and-geopandas.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe0925",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
